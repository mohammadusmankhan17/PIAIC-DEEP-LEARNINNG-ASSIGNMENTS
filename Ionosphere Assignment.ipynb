{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('ionosphere_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6',\n",
       "       'feature7', 'feature8', 'feature9', 'feature10', 'feature11',\n",
       "       'feature12', 'feature13', 'feature14', 'feature15', 'feature16',\n",
       "       'feature17', 'feature18', 'feature19', 'feature20', 'feature21',\n",
       "       'feature22', 'feature23', 'feature24', 'feature25', 'feature26',\n",
       "       'feature27', 'feature28', 'feature29', 'feature30', 'feature31',\n",
       "       'feature32', 'feature33', 'feature34', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data['label'] = labelencoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02337</td>\n",
       "      <td>-0.00592</td>\n",
       "      <td>-0.09924</td>\n",
       "      <td>-0.11949</td>\n",
       "      <td>-0.00763</td>\n",
       "      <td>-0.11824</td>\n",
       "      <td>0.14706</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01535</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.09223</td>\n",
       "      <td>-0.07859</td>\n",
       "      <td>0.00732</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00039</td>\n",
       "      <td>0.12011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97588</td>\n",
       "      <td>-0.10602</td>\n",
       "      <td>0.94601</td>\n",
       "      <td>-0.20800</td>\n",
       "      <td>0.92806</td>\n",
       "      <td>-0.28350</td>\n",
       "      <td>0.85996</td>\n",
       "      <td>-0.27342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.81634</td>\n",
       "      <td>0.13659</td>\n",
       "      <td>-0.82510</td>\n",
       "      <td>0.04606</td>\n",
       "      <td>-0.82395</td>\n",
       "      <td>-0.04262</td>\n",
       "      <td>-0.81318</td>\n",
       "      <td>-0.13832</td>\n",
       "      <td>-0.80975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96355</td>\n",
       "      <td>-0.07198</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.21313</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.36174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65440</td>\n",
       "      <td>0.57577</td>\n",
       "      <td>-0.69712</td>\n",
       "      <td>0.25435</td>\n",
       "      <td>-0.63919</td>\n",
       "      <td>0.45114</td>\n",
       "      <td>-0.72779</td>\n",
       "      <td>0.38895</td>\n",
       "      <td>-0.73420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01864</td>\n",
       "      <td>-0.08459</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>-0.26810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01326</td>\n",
       "      <td>0.20645</td>\n",
       "      <td>-0.02294</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16595</td>\n",
       "      <td>0.24086</td>\n",
       "      <td>-0.08208</td>\n",
       "      <td>0.38065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "5         1         0   0.02337  -0.00592  -0.09924  -0.11949  -0.00763   \n",
       "6         1         0   0.97588  -0.10602   0.94601  -0.20800   0.92806   \n",
       "7         0         0   0.00000   0.00000   0.00000   0.00000   1.00000   \n",
       "8         1         0   0.96355  -0.07198   1.00000  -0.14333   1.00000   \n",
       "9         1         0  -0.01864  -0.08459   0.00000   0.00000   0.00000   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "5  -0.11824   0.14706    0.06637  ...   -0.01535   -0.03240    0.09223   \n",
       "6  -0.28350   0.85996   -0.27342  ...   -0.81634    0.13659   -0.82510   \n",
       "7  -1.00000   0.00000    0.00000  ...    1.00000    1.00000    1.00000   \n",
       "8  -0.21313   1.00000   -0.36174  ...   -0.65440    0.57577   -0.69712   \n",
       "9   0.00000   0.11470   -0.26810  ...   -0.01326    0.20645   -0.02294   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      1  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      0  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      1  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      0  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      1  \n",
       "5   -0.07859    0.00732    0.00000    0.00000   -0.00039    0.12011      0  \n",
       "6    0.04606   -0.82395   -0.04262   -0.81318   -0.13832   -0.80975      1  \n",
       "7    0.00000    0.00000    1.00000    1.00000    0.00000    0.00000      0  \n",
       "8    0.25435   -0.63919    0.45114   -0.72779    0.38895   -0.73420      1  \n",
       "9    0.00000    0.00000    0.16595    0.24086   -0.08208    0.38065      0  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,  Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state= 0 )\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(x.shape[1],)))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                560       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 849\n",
      "Trainable params: 849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 196 samples, validate on 49 samples\n",
      "Epoch 1/20\n",
      "196/196 [==============================] - 1s 6ms/sample - loss: 0.6897 - accuracy: 0.5918 - val_loss: 0.6279 - val_accuracy: 0.6327\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 0s 97us/sample - loss: 0.6628 - accuracy: 0.6173 - val_loss: 0.6051 - val_accuracy: 0.6939\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 0s 107us/sample - loss: 0.6467 - accuracy: 0.6327 - val_loss: 0.5881 - val_accuracy: 0.7143\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 0s 82us/sample - loss: 0.6348 - accuracy: 0.6531 - val_loss: 0.5748 - val_accuracy: 0.7551\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 0s 102us/sample - loss: 0.6255 - accuracy: 0.6582 - val_loss: 0.5636 - val_accuracy: 0.7551\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 0s 87us/sample - loss: 0.6177 - accuracy: 0.6633 - val_loss: 0.5541 - val_accuracy: 0.7551\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 0s 71us/sample - loss: 0.6107 - accuracy: 0.6633 - val_loss: 0.5457 - val_accuracy: 0.7551\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 0s 97us/sample - loss: 0.6045 - accuracy: 0.6633 - val_loss: 0.5383 - val_accuracy: 0.7551\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 0s 87us/sample - loss: 0.5987 - accuracy: 0.6633 - val_loss: 0.5314 - val_accuracy: 0.7551\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 0s 61us/sample - loss: 0.5934 - accuracy: 0.6684 - val_loss: 0.5251 - val_accuracy: 0.7551\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 0s 112us/sample - loss: 0.5885 - accuracy: 0.6735 - val_loss: 0.5191 - val_accuracy: 0.7551\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 0s 97us/sample - loss: 0.5838 - accuracy: 0.6735 - val_loss: 0.5133 - val_accuracy: 0.7551\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 0s 82us/sample - loss: 0.5793 - accuracy: 0.6735 - val_loss: 0.5080 - val_accuracy: 0.7755\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 0s 107us/sample - loss: 0.5750 - accuracy: 0.6735 - val_loss: 0.5029 - val_accuracy: 0.7755\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 0s 72us/sample - loss: 0.5708 - accuracy: 0.6735 - val_loss: 0.4981 - val_accuracy: 0.7755\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 0s 97us/sample - loss: 0.5668 - accuracy: 0.6735 - val_loss: 0.4936 - val_accuracy: 0.7755\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 0s 82us/sample - loss: 0.5629 - accuracy: 0.6786 - val_loss: 0.4895 - val_accuracy: 0.7755\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 0s 92us/sample - loss: 0.5590 - accuracy: 0.6786 - val_loss: 0.4851 - val_accuracy: 0.7755\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 0s 92us/sample - loss: 0.5551 - accuracy: 0.6786 - val_loss: 0.4810 - val_accuracy: 0.7755\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 0s 77us/sample - loss: 0.5512 - accuracy: 0.6837 - val_loss: 0.4770 - val_accuracy: 0.7755\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Vlidation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 104us/sample - loss: 0.5468 - accuracy: 0.6981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5467529454321232, 0.6981132]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing fold # 0\n",
      "\n",
      "....................................................................................................\n",
      "processing fold # 1\n",
      "\n",
      "....................................................................................................\n",
      "processing fold # 2\n",
      "\n",
      "....................................................................................................\n",
      "processing fold # 3\n",
      "\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(X_train) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('\\nprocessing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = X_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = Y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [X_train[:i * num_val_samples],\n",
    "         X_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [Y_train[:i * num_val_samples],\n",
    "         Y_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = model\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=0 , callbacks=[PrintDot()])\n",
    "    # Evaluate the model on the validation data\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.85714287, 0.9591837, 0.93877554, 0.97959185]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9336735"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Some memory clean-up\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing fold # 0\n",
      "\n",
      "...........\n",
      "processing fold # 1\n",
      "\n",
      "...........\n",
      "processing fold # 2\n",
      "\n",
      "...........\n",
      "processing fold # 3\n",
      "\n",
      "................."
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('\\nprocessing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = X_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = Y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [X_train[:i * num_val_samples],\n",
    "         X_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [Y_train[:i * num_val_samples],\n",
    "         Y_train[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = model\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=0, callbacks=[early_stop ,PrintDot()])\n",
    "    val_history = history.history['val_accuracy']\n",
    "    all_mae_histories.append(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "16\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(len(all_mae_histories[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 196 samples\n",
      "Epoch 1/80\n",
      "196/196 [==============================] - 0s 240us/sample - loss: 8.2888e-10 - accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "196/196 [==============================] - 0s 214us/sample - loss: 8.5054e-10 - accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "196/196 [==============================] - 0s 214us/sample - loss: 8.6602e-10 - accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "196/196 [==============================] - 0s 174us/sample - loss: 8.8502e-10 - accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "196/196 [==============================] - 0s 189us/sample - loss: 8.9962e-10 - accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 9.1856e-10 - accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 9.3373e-10 - accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "196/196 [==============================] - 0s 199us/sample - loss: 9.5870e-10 - accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "196/196 [==============================] - 0s 179us/sample - loss: 9.8066e-10 - accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 9.9431e-10 - accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "196/196 [==============================] - 0s 199us/sample - loss: 1.0072e-09 - accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 1.0244e-09 - accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "196/196 [==============================] - 0s 214us/sample - loss: 1.0366e-09 - accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "196/196 [==============================] - 0s 235us/sample - loss: 1.0623e-09 - accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "196/196 [==============================] - 0s 255us/sample - loss: 1.0781e-09 - accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 1.0958e-09 - accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 1.1108e-09 - accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.1388e-09 - accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "196/196 [==============================] - 0s 199us/sample - loss: 1.1554e-09 - accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.1754e-09 - accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "196/196 [==============================] - 0s 179us/sample - loss: 1.1910e-09 - accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "196/196 [==============================] - 0s 169us/sample - loss: 1.2125e-09 - accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 1.2263e-09 - accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.2461e-09 - accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "196/196 [==============================] - 0s 179us/sample - loss: 1.1775e-09 - accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "196/196 [==============================] - 0s 230us/sample - loss: 9.2870e-10 - accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "196/196 [==============================] - 0s 199us/sample - loss: 9.3630e-10 - accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 9.5397e-10 - accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 9.7181e-10 - accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 9.9275e-10 - accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 1.0013e-09 - accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 1.0266e-09 - accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "196/196 [==============================] - 0s 209us/sample - loss: 1.0420e-09 - accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "196/196 [==============================] - 0s 220us/sample - loss: 1.0514e-09 - accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "196/196 [==============================] - 0s 235us/sample - loss: 1.0721e-09 - accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 1.0859e-09 - accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "196/196 [==============================] - 0s 189us/sample - loss: 1.1007e-09 - accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 1.1195e-09 - accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "196/196 [==============================] - 0s 199us/sample - loss: 1.1297e-09 - accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "196/196 [==============================] - 0s 235us/sample - loss: 1.1547e-09 - accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "196/196 [==============================] - 0s 260us/sample - loss: 1.1657e-09 - accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "196/196 [==============================] - 0s 240us/sample - loss: 1.1858e-09 - accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.2027e-09 - accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.2161e-09 - accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 1.2448e-09 - accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.2710e-09 - accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.2778e-09 - accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.2928e-09 - accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.3145e-09 - accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 1.3221e-09 - accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 7.2930e-10 - accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 7.4520e-10 - accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "196/196 [==============================] - 0s 194us/sample - loss: 7.5310e-10 - accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "196/196 [==============================] - 0s 199us/sample - loss: 7.6827e-10 - accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "196/196 [==============================] - 0s 174us/sample - loss: 7.7954e-10 - accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "196/196 [==============================] - 0s 199us/sample - loss: 7.9269e-10 - accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "196/196 [==============================] - 0s 174us/sample - loss: 8.0466e-10 - accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "196/196 [==============================] - 0s 179us/sample - loss: 8.3678e-10 - accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "196/196 [==============================] - 0s 204us/sample - loss: 8.4217e-10 - accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 8.6021e-10 - accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "196/196 [==============================] - 0s 189us/sample - loss: 8.7087e-10 - accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 8.8294e-10 - accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 8.9958e-10 - accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "196/196 [==============================] - 0s 174us/sample - loss: 9.0807e-10 - accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.1305e-10 - accuracy: 1.00 - 0s 169us/sample - loss: 9.2198e-10 - accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "196/196 [==============================] - 0s 158us/sample - loss: 9.3506e-10 - accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "196/196 [==============================] - 0s 169us/sample - loss: 9.4479e-10 - accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "196/196 [==============================] - 0s 214us/sample - loss: 9.6284e-10 - accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "196/196 [==============================] - 0s 255us/sample - loss: 9.7627e-10 - accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "196/196 [==============================] - 0s 209us/sample - loss: 9.9263e-10 - accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 1.0043e-09 - accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "196/196 [==============================] - 0s 184us/sample - loss: 1.0126e-09 - accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "196/196 [==============================] - 0s 179us/sample - loss: 1.0253e-09 - accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "196/196 [==============================] - 0s 174us/sample - loss: 1.0508e-09 - accuracy: 1.0000\n",
      "Epoch 75/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 189us/sample - loss: 1.0614e-09 - accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "196/196 [==============================] - 0s 189us/sample - loss: 1.0692e-09 - accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "196/196 [==============================] - 0s 215us/sample - loss: 1.0839e-09 - accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "196/196 [==============================] - 0s 245us/sample - loss: 1.0972e-09 - accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "196/196 [==============================] - 0s 260us/sample - loss: 1.1138e-09 - accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "196/196 [==============================] - 0s 245us/sample - loss: 6.9795e-10 - accuracy: 1.0000\n",
      "106/106 [==============================] - 0s 151us/sample - loss: 1.9893 - accuracy: 0.9151\n"
     ]
    }
   ],
   "source": [
    "# Get a fresh, compiled model.\n",
    "model = model\n",
    "# Train it on the entirety of the data.\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=80, batch_size=16, verbose=1)\n",
    "test_mse_score, test_mae_score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9150943"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=y_hat.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat=np.array(y_hat.ravel(), dtype=np.int32)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_array=Y_test==y_hat\n",
    "len(bool_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.count_nonzero(bool_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(50, activation='relu', kernel_initializer='he_normal', input_shape=(x.shape[1],)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(layers.Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_build2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 50)                1750      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,271\n",
      "Trainable params: 2,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 196 samples, validate on 49 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 1s 6ms/sample - loss: 0.7267 - accuracy: 0.6173 - val_loss: 0.5835 - val_accuracy: 0.7551\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 546us/sample - loss: 0.6803 - accuracy: 0.6684 - val_loss: 0.5538 - val_accuracy: 0.7551\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 511us/sample - loss: 0.6670 - accuracy: 0.6837 - val_loss: 0.5269 - val_accuracy: 0.7755\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 470us/sample - loss: 0.6252 - accuracy: 0.6633 - val_loss: 0.4981 - val_accuracy: 0.7755\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 552us/sample - loss: 0.5751 - accuracy: 0.6888 - val_loss: 0.4705 - val_accuracy: 0.7755\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 475us/sample - loss: 0.5621 - accuracy: 0.7245 - val_loss: 0.4547 - val_accuracy: 0.8163\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 0s 480us/sample - loss: 0.5480 - accuracy: 0.7194 - val_loss: 0.4330 - val_accuracy: 0.8163\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 0s 526us/sample - loss: 0.5486 - accuracy: 0.7398 - val_loss: 0.4228 - val_accuracy: 0.8163\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 557us/sample - loss: 0.5106 - accuracy: 0.7857 - val_loss: 0.4182 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 546us/sample - loss: 0.4979 - accuracy: 0.7551 - val_loss: 0.4021 - val_accuracy: 0.8776\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 0s 490us/sample - loss: 0.4749 - accuracy: 0.7653 - val_loss: 0.3874 - val_accuracy: 0.8980\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 0s 460us/sample - loss: 0.4478 - accuracy: 0.8112 - val_loss: 0.3670 - val_accuracy: 0.9184\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 0s 475us/sample - loss: 0.4559 - accuracy: 0.8418 - val_loss: 0.3530 - val_accuracy: 0.8980\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 0s 490us/sample - loss: 0.4467 - accuracy: 0.8010 - val_loss: 0.3510 - val_accuracy: 0.9184\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 0s 521us/sample - loss: 0.3934 - accuracy: 0.8265 - val_loss: 0.3357 - val_accuracy: 0.8980\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 0s 490us/sample - loss: 0.3905 - accuracy: 0.8418 - val_loss: 0.3208 - val_accuracy: 0.8980\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 0s 475us/sample - loss: 0.3790 - accuracy: 0.8929 - val_loss: 0.3020 - val_accuracy: 0.8980\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 0s 480us/sample - loss: 0.3645 - accuracy: 0.8622 - val_loss: 0.2910 - val_accuracy: 0.8980\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 0s 485us/sample - loss: 0.3576 - accuracy: 0.8673 - val_loss: 0.2866 - val_accuracy: 0.8980\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 0s 582us/sample - loss: 0.3388 - accuracy: 0.8878 - val_loss: 0.2827 - val_accuracy: 0.9184\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 0s 562us/sample - loss: 0.3624 - accuracy: 0.8469 - val_loss: 0.2721 - val_accuracy: 0.9184\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 0s 490us/sample - loss: 0.3392 - accuracy: 0.8571 - val_loss: 0.2619 - val_accuracy: 0.9184\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 0s 485us/sample - loss: 0.2765 - accuracy: 0.8929 - val_loss: 0.2570 - val_accuracy: 0.9184\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 0s 511us/sample - loss: 0.2772 - accuracy: 0.9031 - val_loss: 0.2462 - val_accuracy: 0.9184\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 0s 546us/sample - loss: 0.2895 - accuracy: 0.8929 - val_loss: 0.2378 - val_accuracy: 0.9184\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 0s 495us/sample - loss: 0.2777 - accuracy: 0.8980 - val_loss: 0.2336 - val_accuracy: 0.9184\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 0s 434us/sample - loss: 0.2599 - accuracy: 0.9184 - val_loss: 0.2312 - val_accuracy: 0.9184\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 0s 470us/sample - loss: 0.2507 - accuracy: 0.9082 - val_loss: 0.2265 - val_accuracy: 0.9184\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 0s 516us/sample - loss: 0.2429 - accuracy: 0.9184 - val_loss: 0.2199 - val_accuracy: 0.9184\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 0s 521us/sample - loss: 0.2372 - accuracy: 0.9235 - val_loss: 0.2130 - val_accuracy: 0.9184\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 0s 567us/sample - loss: 0.2406 - accuracy: 0.9235 - val_loss: 0.2191 - val_accuracy: 0.9184\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 0s 582us/sample - loss: 0.2049 - accuracy: 0.9490 - val_loss: 0.2128 - val_accuracy: 0.9184\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 0s 557us/sample - loss: 0.1997 - accuracy: 0.9337 - val_loss: 0.2057 - val_accuracy: 0.9184\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 0s 516us/sample - loss: 0.2308 - accuracy: 0.9133 - val_loss: 0.2113 - val_accuracy: 0.9184\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 0s 495us/sample - loss: 0.1977 - accuracy: 0.9337 - val_loss: 0.2048 - val_accuracy: 0.9184\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 0s 465us/sample - loss: 0.2114 - accuracy: 0.9337 - val_loss: 0.2068 - val_accuracy: 0.9184\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 0s 531us/sample - loss: 0.2065 - accuracy: 0.9286 - val_loss: 0.2086 - val_accuracy: 0.9184\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 0s 454us/sample - loss: 0.1997 - accuracy: 0.9439 - val_loss: 0.2021 - val_accuracy: 0.9184\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 0s 444us/sample - loss: 0.2037 - accuracy: 0.9337 - val_loss: 0.2005 - val_accuracy: 0.9184\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 0s 424us/sample - loss: 0.1844 - accuracy: 0.9337 - val_loss: 0.1960 - val_accuracy: 0.9184\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 0s 439us/sample - loss: 0.1898 - accuracy: 0.9337 - val_loss: 0.1877 - val_accuracy: 0.9184\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 0s 567us/sample - loss: 0.1867 - accuracy: 0.9541 - val_loss: 0.1801 - val_accuracy: 0.9184\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 0s 500us/sample - loss: 0.1567 - accuracy: 0.9541 - val_loss: 0.1819 - val_accuracy: 0.9184\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 0s 592us/sample - loss: 0.1546 - accuracy: 0.9490 - val_loss: 0.1757 - val_accuracy: 0.9184\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 0s 403us/sample - loss: 0.1735 - accuracy: 0.9439 - val_loss: 0.1735 - val_accuracy: 0.9184\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 0s 521us/sample - loss: 0.1845 - accuracy: 0.9235 - val_loss: 0.1706 - val_accuracy: 0.9184\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 0s 567us/sample - loss: 0.1721 - accuracy: 0.9694 - val_loss: 0.1781 - val_accuracy: 0.9184\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 0s 531us/sample - loss: 0.1453 - accuracy: 0.9592 - val_loss: 0.1743 - val_accuracy: 0.9184\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 0s 419us/sample - loss: 0.1514 - accuracy: 0.9592 - val_loss: 0.1779 - val_accuracy: 0.9184\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 0s 500us/sample - loss: 0.1310 - accuracy: 0.9592 - val_loss: 0.1737 - val_accuracy: 0.9184\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 0s 485us/sample - loss: 0.1742 - accuracy: 0.9337 - val_loss: 0.1679 - val_accuracy: 0.9184\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 0s 516us/sample - loss: 0.1380 - accuracy: 0.9592 - val_loss: 0.1659 - val_accuracy: 0.9184\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 0s 572us/sample - loss: 0.1577 - accuracy: 0.9643 - val_loss: 0.1658 - val_accuracy: 0.9184\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 0s 577us/sample - loss: 0.1392 - accuracy: 0.9643 - val_loss: 0.1594 - val_accuracy: 0.9184\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 0s 552us/sample - loss: 0.1339 - accuracy: 0.9592 - val_loss: 0.1593 - val_accuracy: 0.9184\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 454us/sample - loss: 0.1270 - accuracy: 0.9745 - val_loss: 0.1632 - val_accuracy: 0.9184\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 0s 434us/sample - loss: 0.1387 - accuracy: 0.9541 - val_loss: 0.1718 - val_accuracy: 0.9184\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 0s 398us/sample - loss: 0.1430 - accuracy: 0.9541 - val_loss: 0.1749 - val_accuracy: 0.9184\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 0s 347us/sample - loss: 0.1291 - accuracy: 0.9541 - val_loss: 0.1800 - val_accuracy: 0.9184\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 0s 398us/sample - loss: 0.1283 - accuracy: 0.9592 - val_loss: 0.1815 - val_accuracy: 0.9184\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 0s 465us/sample - loss: 0.1027 - accuracy: 0.9745 - val_loss: 0.1724 - val_accuracy: 0.9184\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 0s 597us/sample - loss: 0.0954 - accuracy: 0.9694 - val_loss: 0.1659 - val_accuracy: 0.9184\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 0s 618us/sample - loss: 0.0918 - accuracy: 0.9694 - val_loss: 0.1690 - val_accuracy: 0.9184\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 0s 649us/sample - loss: 0.0705 - accuracy: 0.9898 - val_loss: 0.1736 - val_accuracy: 0.9184\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 0s 475us/sample - loss: 0.1063 - accuracy: 0.9745 - val_loss: 0.1679 - val_accuracy: 0.9184\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 0s 511us/sample - loss: 0.0839 - accuracy: 0.9898 - val_loss: 0.1743 - val_accuracy: 0.9388\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 0s 403us/sample - loss: 0.1051 - accuracy: 0.9745 - val_loss: 0.1816 - val_accuracy: 0.9388\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 0s 409us/sample - loss: 0.1094 - accuracy: 0.9694 - val_loss: 0.1671 - val_accuracy: 0.9184\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 0s 409us/sample - loss: 0.1478 - accuracy: 0.9643 - val_loss: 0.1661 - val_accuracy: 0.9184\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 0s 567us/sample - loss: 0.1070 - accuracy: 0.9643 - val_loss: 0.1625 - val_accuracy: 0.9388\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 0s 552us/sample - loss: 0.1156 - accuracy: 0.9643 - val_loss: 0.1711 - val_accuracy: 0.9388\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 0s 546us/sample - loss: 0.0859 - accuracy: 0.9847 - val_loss: 0.1767 - val_accuracy: 0.9388\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 0s 485us/sample - loss: 0.0887 - accuracy: 0.9745 - val_loss: 0.1706 - val_accuracy: 0.9388\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 0s 480us/sample - loss: 0.0896 - accuracy: 0.9796 - val_loss: 0.1688 - val_accuracy: 0.9184\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 0s 562us/sample - loss: 0.0998 - accuracy: 0.9643 - val_loss: 0.1658 - val_accuracy: 0.9388\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 0s 562us/sample - loss: 0.0975 - accuracy: 0.9592 - val_loss: 0.1545 - val_accuracy: 0.9388\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 0s 536us/sample - loss: 0.0829 - accuracy: 0.9745 - val_loss: 0.1560 - val_accuracy: 0.9388\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 0s 475us/sample - loss: 0.0807 - accuracy: 0.9745 - val_loss: 0.1658 - val_accuracy: 0.9388\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 0s 567us/sample - loss: 0.0766 - accuracy: 0.9745 - val_loss: 0.1665 - val_accuracy: 0.9592\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 0s 567us/sample - loss: 0.0779 - accuracy: 0.9745 - val_loss: 0.1808 - val_accuracy: 0.9184\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 0s 434us/sample - loss: 0.0706 - accuracy: 0.9796 - val_loss: 0.1746 - val_accuracy: 0.9388\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 0s 444us/sample - loss: 0.0862 - accuracy: 0.9643 - val_loss: 0.1647 - val_accuracy: 0.9388\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 0s 597us/sample - loss: 0.0435 - accuracy: 0.9949 - val_loss: 0.1699 - val_accuracy: 0.9388\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 0s 506us/sample - loss: 0.1084 - accuracy: 0.9592 - val_loss: 0.1651 - val_accuracy: 0.9388\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 0s 506us/sample - loss: 0.0810 - accuracy: 0.9745 - val_loss: 0.1728 - val_accuracy: 0.9388\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 0s 628us/sample - loss: 0.0841 - accuracy: 0.9796 - val_loss: 0.1656 - val_accuracy: 0.9388\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 0s 643us/sample - loss: 0.0677 - accuracy: 0.9847 - val_loss: 0.1597 - val_accuracy: 0.9388\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 0s 577us/sample - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.1592 - val_accuracy: 0.9592\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 0s 521us/sample - loss: 0.0930 - accuracy: 0.9745 - val_loss: 0.1647 - val_accuracy: 0.9388\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 0s 475us/sample - loss: 0.0624 - accuracy: 0.9898 - val_loss: 0.1632 - val_accuracy: 0.9388\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 0s 490us/sample - loss: 0.0570 - accuracy: 0.9898 - val_loss: 0.1586 - val_accuracy: 0.9388\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 0s 516us/sample - loss: 0.0556 - accuracy: 0.9898 - val_loss: 0.1573 - val_accuracy: 0.9388\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 0s 506us/sample - loss: 0.0627 - accuracy: 0.9796 - val_loss: 0.1583 - val_accuracy: 0.9388\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 0s 521us/sample - loss: 0.0668 - accuracy: 0.9796 - val_loss: 0.1634 - val_accuracy: 0.9388\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 0s 567us/sample - loss: 0.0552 - accuracy: 0.9847 - val_loss: 0.1662 - val_accuracy: 0.9388\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 0s 592us/sample - loss: 0.0684 - accuracy: 0.9847 - val_loss: 0.1533 - val_accuracy: 0.9592\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 0s 521us/sample - loss: 0.0412 - accuracy: 0.9949 - val_loss: 0.1632 - val_accuracy: 0.9388\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 0s 608us/sample - loss: 0.0788 - accuracy: 0.9643 - val_loss: 0.1574 - val_accuracy: 0.9592\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 0s 444us/sample - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.1586 - val_accuracy: 0.9592\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 0s 526us/sample - loss: 0.0672 - accuracy: 0.9745 - val_loss: 0.1562 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xd3524458d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=8, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 151us/sample - loss: 0.1248 - accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12478926215531691, 0.9811321]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat=model.predict(X_test)\n",
    "y_hat=np.array((y_hat.ravel()).round(), dtype=np.int32)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_value=Y_test=y_hat\n",
    "boolean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.count_nonzero(bool_array)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.50943396226415"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=(97/106)*100\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
